{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Positive & Negative Movie Reviews Classification.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"m_jUYJVMT0Ms","colab_type":"code","colab":{}},"source":["import nltk\n","nltk.download('popular')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDP4eDrqSxhC","colab_type":"code","outputId":"759377c6-1281-4ef9-d7b7-554aeef547d6","executionInfo":{"status":"ok","timestamp":1586152560094,"user_tz":-360,"elapsed":7685,"user":{"displayName":"Nishat Tasnim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6aI9dJiRS9PZVcrdlf4biLa45mUf1kUqW_7kE=s64","userId":"02350111961180247447"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["import random\n","from nltk.corpus import movie_reviews\n","\n","documents = [(list(movie_reviews.words(fileid)), category)\n","             for category in movie_reviews.categories()\n","             for fileid in movie_reviews.fileids(category)]\n","\n","# shuffle the documents\n","random.shuffle(documents)\n","\n","print('Number of Documents: {}'.format(len(documents)))\n","print('First Review: {}'.format(documents[1]))\n","\n","all_words = []\n","for w in movie_reviews.words():\n","    all_words.append(w.lower())\n","\n","all_words = nltk.FreqDist(all_words)\n","\n","print('Most common words: {}'.format(all_words.most_common(15)))\n","print('The word happy: {}'.format(all_words[\"happy\"]))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Number of Documents: 2000\n","First Review: (['bob', 'the', 'happy', 'bastard', \"'\", 's', 'quickie', 'review', ':', 'the', 'mummy', 'brendan', 'fraser', \"'\", 's', 'stuck', 'in', 'the', 'past', 'again', ',', 'but', 'at', 'least', 'this', 'time', 'he', 'has', 'something', 'better', 'to', 'do', 'than', 'to', 'quote', 'sitcom', 'lines', 'and', 'try', 'to', 'woo', 'alicia', 'silverstone', '.', '.', '.', 'fraser', 'is', 'the', 'lead', 'star', 'of', 'the', 'mummy', ',', 'the', 'second', 'directorial', 'effort', 'from', 'action', 'director', 'stephen', 'sommers', '(', 'who', 'also', 'brought', 'us', 'the', 'decent', 'thrill', 'ride', 'that', 'was', 'deep', 'rising', ')', '.', 'it', \"'\", 's', 'a', 'rough', 'adaptation', 'of', 'the', '1932', 'film', ',', 'and', 'i', 'say', 'rough', 'because', 'it', 'focuses', 'more', 'on', 'special', 'effects', 'than', 'on', 'some', 'guy', 'in', 'bandages', ',', 'like', 'boris', 'karloff', 'was', 'engulfed', 'in', '.', 'but', 'who', 'cares', ',', 'the', 'movie', 'has', 'a', 'sort', 'of', 'swashbuckling', 'quality', 'to', 'it', 'you', 'can', \"'\", 't', 'get', 'from', ',', 'oh', ',', 'say', ',', 'godzilla', 'or', 'armageddon', '.', 'fraser', 'plays', 'a', 'soldier', 'who', 'gets', 'a', 'premonition', 'during', 'a', 'battle', 'with', 'soldiers', 'in', 'an', 'egyptian', 'ground', '.', 'basically', ',', 'it', \"'\", 's', 'a', 'little', 'sign', 'from', 'the', 'mummy', 'buried', 'underneath', '-', 'a', 'priest', 'named', 'ihmoetep', 'who', 'was', 'buried', 'alive', 'for', 'taking', 'part', 'of', 'murdering', 'the', 'king', 'and', 'making', 'out', 'with', 'his', 'mistress', '.', 'his', 'plan', '-', 'wake', 'back', 'up', 'and', 'wake', 'her', 'up', 'also', ',', 'making', 'him', 'invincible', '.', 'of', 'course', ',', 'fraser', 'returns', 'to', 'the', 'site', 'years', 'later', 'with', 'a', 'librarian', '(', 'rachel', 'weisz', ')', 'and', 'her', 'brother', '(', 'john', 'hanna', ')', ',', 'along', 'with', 'a', 'former', 'buddy', 'of', 'his', '(', 'deep', 'rising', \"'\", 's', 'kevin', 'j', '.', 'o', \"'\", 'connor', ')', 'and', 'some', '\"', 'americans', '\"', '.', '.', '.', 'and', 'guess', 'what', '?', 'yup', ',', 'ihmoetep', '(', 'arnold', 'vosloo', ')', 'awakens', 'and', 'wreaks', 'havoc', '.', 'fire', 'flies', 'from', 'the', 'sky', ',', 'flesh', '-', 'eating', 'beetles', 'crawl', 'about', ',', 'and', ',', 'well', ',', 'ihmoetep', \"'\", 's', 'plan', 'begins', 'to', 'unfold', '.', 'ok', ',', 'so', 'it', \"'\", 's', 'not', 'really', 'all', 'that', 'new', 'a', 'story', ',', 'but', 'the', 'way', 'sommers', 'tells', 'it', 'is', 'entertaining', 'enough', '.', 'the', 'special', 'effects', 'from', 'industrial', 'light', 'and', 'magic', 'are', 'top', 'notch', ',', 'and', 'the', 'acting', 'from', 'fraser', 'and', 'weisz', 'isn', \"'\", 't', 'half', 'bad', 'either', '.', 'the', 'action', 'is', 'pretty', 'intense', '(', 'favorite', 'scene', ':', 'the', 'sandstorm', ')', 'and', 'there', 'are', 'a', 'few', 'shocking', 'scenes', 'just', 'to', 'jolt', 'you', 'horror', '-', 'loving', 'folks', 'as', 'well', '.', 'no', ',', 'it', \"'\", 's', 'no', 'phantom', 'menace', 'beater', ',', 'but', 'if', 'you', \"'\", 're', 'looking', 'for', 'a', 'solid', 'warm', '-', 'up', 'to', 'the', 'summer', 'movie', 'season', ',', 'you', 'won', \"'\", 't', 'find', 'a', 'better', 'film', 'under', 'wraps', 'than', 'the', 'mummy', '.', 'if', 'this', 'doesn', \"'\", 't', 'give', 'fraser', 'forgiveness', 'from', 'blast', 'from', 'the', 'past', 'and', 'encino', 'man', ',', 'then', 'nothing', 'will', '.'], 'pos')\n","Most common words: [(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n","The word happy: 215\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IB94WyhlSxhH","colab_type":"code","outputId":"83ab3abf-bb48-4853-eb60-b24ee40ea5a0","executionInfo":{"status":"ok","timestamp":1586152560095,"user_tz":-360,"elapsed":7660,"user":{"displayName":"Nishat Tasnim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6aI9dJiRS9PZVcrdlf4biLa45mUf1kUqW_7kE=s64","userId":"02350111961180247447"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# We'll use the 4000 most common words as features\n","print(len(all_words))\n","word_features = list(all_words.keys())[:4000]"],"execution_count":3,"outputs":[{"output_type":"stream","text":["39768\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f6nyuXl7SxhP","colab_type":"code","outputId":"31388b36-0d64-4775-8268-1b142323ee77","executionInfo":{"status":"ok","timestamp":1586152560097,"user_tz":-360,"elapsed":7639,"user":{"displayName":"Nishat Tasnim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6aI9dJiRS9PZVcrdlf4biLa45mUf1kUqW_7kE=s64","userId":"02350111961180247447"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# The find_features function will determine which of the 3000 word features are contained in the review\n","def find_features(document):\n","    words = set(document)\n","    features = {}\n","    for w in word_features:\n","        features[w] = (w in words)\n","\n","    return features\n","\n","\n","# Lets use an example from a negative review\n","features = find_features(movie_reviews.words('neg/cv000_29416.txt'))\n","for key, value in features.items():\n","    if value == True:\n","        print(key)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["plot\n",":\n","two\n","teen\n","couples\n","go\n","to\n","a\n","church\n","party\n",",\n","drink\n","and\n","then\n","drive\n",".\n","they\n","get\n","into\n","an\n","accident\n","one\n","of\n","the\n","guys\n","dies\n","but\n","his\n","girlfriend\n","continues\n","see\n","him\n","in\n","her\n","life\n","has\n","nightmares\n","what\n","'\n","s\n","deal\n","?\n","watch\n","movie\n","\"\n","sorta\n","find\n","out\n","critique\n","mind\n","-\n","fuck\n","for\n","generation\n","that\n","touches\n","on\n","very\n","cool\n","idea\n","presents\n","it\n","bad\n","package\n","which\n","is\n","makes\n","this\n","review\n","even\n","harder\n","write\n","since\n","i\n","generally\n","applaud\n","films\n","attempt\n","break\n","mold\n","mess\n","with\n","your\n","head\n","such\n","(\n","lost\n","highway\n","&\n","memento\n",")\n","there\n","are\n","good\n","ways\n","making\n","all\n","types\n","these\n","folks\n","just\n","didn\n","t\n","snag\n","correctly\n","seem\n","have\n","taken\n","pretty\n","neat\n","concept\n","executed\n","terribly\n","so\n","problems\n","well\n","its\n","main\n","problem\n","simply\n","too\n","jumbled\n","starts\n","off\n","normal\n","downshifts\n","fantasy\n","world\n","you\n","as\n","audience\n","member\n","no\n","going\n","dreams\n","characters\n","coming\n","back\n","from\n","dead\n","others\n","who\n","look\n","like\n","strange\n","apparitions\n","disappearances\n","looooot\n","chase\n","scenes\n","tons\n","weird\n","things\n","happen\n","most\n","not\n","explained\n","now\n","personally\n","don\n","trying\n","unravel\n","film\n","every\n","when\n","does\n","give\n","me\n","same\n","clue\n","over\n","again\n","kind\n","fed\n","up\n","after\n","while\n","biggest\n","obviously\n","got\n","big\n","secret\n","hide\n","seems\n","want\n","completely\n","until\n","final\n","five\n","minutes\n","do\n","make\n","entertaining\n","thrilling\n","or\n","engaging\n","meantime\n","really\n","sad\n","part\n","arrow\n","both\n","dig\n","flicks\n","we\n","actually\n","figured\n","by\n","half\n","way\n","point\n","strangeness\n","did\n","start\n","little\n","bit\n","sense\n","still\n","more\n","guess\n","bottom\n","line\n","movies\n","should\n","always\n","sure\n","before\n","given\n","password\n","enter\n","understanding\n","mean\n","showing\n","melissa\n","sagemiller\n","running\n","away\n","visions\n","about\n","20\n","throughout\n","plain\n","lazy\n","!\n","okay\n","people\n","chasing\n","know\n","need\n","how\n","giving\n","us\n","different\n","offering\n","further\n","insight\n","down\n","apparently\n","studio\n","took\n","director\n","chopped\n","themselves\n","shows\n","might\n","ve\n","been\n","decent\n","here\n","somewhere\n","suits\n","decided\n","turning\n","music\n","video\n","edge\n","would\n","actors\n","although\n","wes\n","bentley\n","seemed\n","be\n","playing\n","exact\n","character\n","he\n","american\n","beauty\n","only\n","new\n","neighborhood\n","my\n","kudos\n","holds\n","own\n","entire\n","feeling\n","unraveling\n","overall\n","doesn\n","stick\n","because\n","entertain\n","confusing\n","rarely\n","excites\n","feels\n","redundant\n","runtime\n","despite\n","ending\n","explanation\n","craziness\n","came\n","oh\n","horror\n","slasher\n","flick\n","packaged\n","someone\n","assuming\n","genre\n","hot\n","kids\n","also\n","wrapped\n","production\n","years\n","ago\n","sitting\n","shelves\n","ever\n","whatever\n","skip\n","where\n","joblo\n","nightmare\n","elm\n","street\n","3\n","7\n","/\n","10\n","blair\n","witch\n","2\n","crow\n","9\n","salvation\n","4\n","stir\n","echoes\n","8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o2fh4HqPSxhU","colab_type":"code","colab":{}},"source":["# Now lets do it for all the documents\n","featuresets = [(find_features(rev), category) for (rev, category) in documents]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"833a82V_SxhZ","colab_type":"code","colab":{}},"source":["# we can split the featuresets into training and testing datasets using sklearn\n","from sklearn import model_selection\n","\n","# define a seed for reproducibility\n","seed = 1\n","\n","# split the data into training and testing datasets\n","training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTa_CeMlSxhe","colab_type":"code","outputId":"b08cae48-45b4-4773-be8f-9f0a39adb6fe","executionInfo":{"status":"ok","timestamp":1586152560751,"user_tz":-360,"elapsed":8229,"user":{"displayName":"Nishat Tasnim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6aI9dJiRS9PZVcrdlf4biLa45mUf1kUqW_7kE=s64","userId":"02350111961180247447"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(len(training))\n","print(len(testing))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["1500\n","500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CSslgqknSxhj","colab_type":"code","outputId":"7f23f135-b86a-4bf2-d6d2-bece348c81d1","executionInfo":{"status":"ok","timestamp":1586152586586,"user_tz":-360,"elapsed":34047,"user":{"displayName":"Nishat Tasnim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6aI9dJiRS9PZVcrdlf4biLa45mUf1kUqW_7kE=s64","userId":"02350111961180247447"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# We can use sklearn algorithms in NLTK\n","from nltk.classify.scikitlearn import SklearnClassifier\n","from sklearn.svm import SVC\n","\n","model = SklearnClassifier(SVC(kernel = 'linear'))\n","\n","# train the model on the training data\n","model.train(training)\n","\n","# and test on the testing dataset!\n","accuracy = nltk.classify.accuracy(model, testing)*100\n","print(\"SVC Accuracy: {}\".format(accuracy))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["SVC Accuracy: 80.80000000000001\n"],"name":"stdout"}]}]}